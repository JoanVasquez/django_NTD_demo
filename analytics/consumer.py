import json
import logging
import os
from datetime import datetime, timezone

import django
from kafka import KafkaConsumer
from kafka.errors import KafkaError

from analytics.models import PlanetEvent
from cache.cache_manager import CacheManager

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Bootstrap Django before importing any models
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "app.settings")
django.setup()


# ğŸ“ Setup logging
logger = logging.getLogger(__name__)


def run_consumer():
    # ğŸ”Œ Initialize Kafka consumer with configuration
    consumer = KafkaConsumer(
        "planet_events",
        bootstrap_servers=os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092").split(","),
        value_deserializer=lambda m: json.loads(m.decode("utf-8")),
        auto_offset_reset="earliest",
        enable_auto_commit=True,
        group_id="analytics-consumer",
    )

    logger.info("ğŸ” Starting analytics consumerâ€¦")
    # ğŸ”„ Main consumer loop
    for msg in consumer:
        try:
            # ğŸ“¥ Get event data from message
            evt = msg.value or {}

            # ğŸ’¾ Step 1: Store raw event data in database for audit
            PlanetEvent.objects.create(
                event_type=evt.get("type", ""),
                data=evt.get("data", {}),
            )

            # ğŸ“Š Step 2: Increment counter in Redis for event date
            ts_ms = msg.timestamp or 0  # epoch ms
            day = datetime.fromtimestamp(ts_ms / 1000, tz=timezone.utc).strftime(
                "%Y-%m-%d"
            )
            CacheManager._incr_event_count_for_day(day)

            # âœ… Log successful event processing
            logger.info("âœ… Consumed event", extra={"event": evt})
        except (KafkaError, Exception) as e:
            # âŒ Log any errors that occur
            logger.error("âŒ Error in consumer loop", exc_info=e)


# ğŸš€ Only run the consumer when executed as a script
if __name__ == "__main__":
    run_consumer()
