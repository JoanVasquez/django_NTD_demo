# 🐳 docker-compose.yml — Compose v2 for Django + Kafka + Monitoring

services:

  # 🐘 PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      retries: 5
    networks: [backend]

  # 🚀 Redis (Celery broker + cache)
  redis:
    image: redis:7-alpine
    command: ["redis-server", "--save", "60", "1"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5
    networks: [backend]

  # 🌐 Django App (Gunicorn)
  web:
    build:
      context: .
      target: prod
    command: >
      gunicorn app.wsgi:application
        --bind 0.0.0.0:8000
        --workers 4
        --threads 8
        --worker-class gthread
        --timeout 120
        --preload
    env_file: [.env]
    environment:
      RUN_MIGRATIONS: "1"
    volumes:
      - type: bind
        source: .
        target: /app
        consistency: cached
    ports:
      - "8000:8000"
    depends_on:
      postgres: {condition: service_healthy}
      redis: {condition: service_healthy}
    networks: [backend]

  # 📈 Kafka Consumer (analytics)
  analytics_consumer:
    build:
      context: .
      target: prod
    command: python -m analytics.consumer
    env_file: [.env]
    environment:
      RUN_MIGRATIONS: "0"
    restart: unless-stopped
    depends_on:
      kafka: {condition: service_healthy}
      postgres: {condition: service_started}
    networks: [backend]

  # 🐝 Celery Worker
  celery:
    build:
      context: .
      target: prod
    command: celery -A app worker -l info --autoscale=8,2
    env_file: [.env]
    environment:
      RUN_MIGRATIONS: "0"
    depends_on:
      redis: {condition: service_healthy}
      web: {condition: service_started}
    healthcheck:
      test: ["CMD-SHELL", "celery -A app inspect ping -d celery@$$HOSTNAME | grep -q pong"]
      interval: 30s
      retries: 3
    networks: [backend]

  # ⏱️ Celery Beat Scheduler
  beat:
    build:
      context: .
      target: prod
    env_file: [.env]
    environment:
      RUN_MIGRATIONS: "0"
    command:
      - celery
      - -A
      - app
      - beat
      - -l
      - info
      - --scheduler
      - django_celery_beat.schedulers:DatabaseScheduler
    depends_on:
      redis: {condition: service_healthy}
      celery: {condition: service_healthy}
    networks: [backend]

  # 🌸 Flower Dashboard
  flower:
    image: mher/flower:latest
    env_file: [.env]
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
    command:
      - celery
      - flower
      - --broker=${CELERY_BROKER_URL}
      - --port=5555
      - --url_prefix=flower
    ports:
      - "5555:5555"
    depends_on:
      celery: {condition: service_healthy}
    networks: [backend]

  # 🦓 ZooKeeper for Kafka
  zookeeper:
    image: bitnami/zookeeper:3.8
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "zkServer.sh", "status"]
      interval: 10s
      retries: 5
    networks: [backend]

  # 🐦 Kafka Broker
  kafka:
    image: bitnami/kafka:3.4
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"
    healthcheck:
      test: ["CMD", "/opt/bitnami/kafka/bin/kafka-broker-api-versions.sh", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      zookeeper: {condition: service_healthy}
    networks: [backend]

  # # 🪢 Pre-commit Hooks
  # pre-commit:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #     target: dev
  #   container_name: django_precommit
  #   volumes:
  #     - .:/app:cached
  #   entrypoint: ["pre-commit", "run", "--all-files", "--show-diff-on-failure"]

  # 📊 Redis Exporter
  redis_exporter:
    image: oliver006/redis_exporter:latest
    command: ["--redis.addr=redis://redis:6379"]
    ports:
      - "9121:9121"
    networks: [backend]

  # 🐘 Postgres Exporter
  postgres_exporter:
    image: prometheuscommunity/postgres-exporter:latest
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable"
    ports:
      - "9187:9187"
    networks: [backend]

  # 📈 Prometheus
  prometheus:
    image: prom/prometheus:v2.51.0
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    depends_on:
      - redis_exporter
      - postgres_exporter
    networks: [backend]

  # 📊 Grafana Dashboard
  grafana:
    image: grafana/grafana:10.1.1
    environment:
      GF_SECURITY_ADMIN_PASSWORD: "grafana123"
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks: [backend]

  # 🔎 Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ulimits:
      memlock: {soft: -1, hard: -1}
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: >
        curl -fs http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=1s || exit 1
      interval: 15s
      timeout: 5s
      start_period: 60s
      retries: 10
    networks: [backend]

  # 📦 Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.13.2
    volumes:
      - ./logstash/pipeline/:/usr/share/logstash/pipeline/:ro
    ports:
      - "5044:5044"
      - "5000:5000"
    depends_on:
      elasticsearch: {condition: service_healthy}
    networks: [backend]

  # 🖥️ Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - xpack.security.enabled=false
    ports:
      - "5601:5601"
    depends_on:
      elasticsearch: {condition: service_healthy}
    networks: [backend]

# 🗄️ Persistent Volumes
volumes:
  pgdata:
  grafana_data:
  es_data:

# 🌐 Shared Network
networks:
  backend:
